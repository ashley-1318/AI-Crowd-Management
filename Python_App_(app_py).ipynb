{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ashley-1318/AI-Crowd-Management/blob/main/Python_App_(app_py).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# app.py\n",
        "# Main application for the AI-Based CCTV Network for Crowd Management with Gemini Integration\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "from flask import Flask, render_template, Response, jsonify, request\n",
        "import time\n",
        "import json\n",
        "\n",
        "# Initialize the Flask application\n",
        "app = Flask(__name__)\n",
        "\n",
        "# --- Configuration ---\n",
        "# Load the pre-trained MobileNet SSD model for person detection\n",
        "PROTOTXT = \"MobileNetSSD_deploy.prototxt.txt\"\n",
        "MODEL = \"MobileNetSSD_deploy.caffemodel\"\n",
        "net = cv2.dnn.readNetFromCaffe(PROTOTXT, MODEL)\n",
        "\n",
        "# Confidence threshold for detections\n",
        "CONFIDENCE_THRESHOLD = 0.4\n",
        "\n",
        "# Define the classes the model can detect. We are only interested in 'person'.\n",
        "CLASSES = [\"background\", \"aeroplane\", \"bicycle\", \"bird\", \"boat\",\n",
        "           \"bottle\", \"bus\", \"car\", \"cat\", \"chair\", \"cow\", \"diningtable\",\n",
        "           \"dog\", \"horse\", \"motorbike\", \"person\", \"pottedplant\", \"sheep\",\n",
        "           \"sofa\", \"train\", \"tvmonitor\"]\n",
        "\n",
        "# --- Global State for Status ---\n",
        "# This dictionary will hold the latest analysis results to be accessed by different routes.\n",
        "# This is a simple approach for this example. In a production app, you might use a more robust state management solution.\n",
        "app_status = {\n",
        "    \"person_count\": 0,\n",
        "    \"density_level\": \"Low\",\n",
        "    \"last_updated\": time.time()\n",
        "}\n",
        "\n",
        "# --- Crowd Density Logic ---\n",
        "def analyze_frame(frame):\n",
        "    \"\"\"\n",
        "    Analyzes a single video frame to detect people and estimate crowd density.\n",
        "    Updates the global app_status.\n",
        "\n",
        "    Args:\n",
        "        frame: The input video frame (a NumPy array).\n",
        "\n",
        "    Returns:\n",
        "        The processed frame with bounding boxes and density info.\n",
        "    \"\"\"\n",
        "    global app_status\n",
        "    (h, w) = frame.shape[:2]\n",
        "    blob = cv2.dnn.blobFromImage(cv2.resize(frame, (300, 300)), 0.007843, (300, 300), 127.5)\n",
        "\n",
        "    net.setInput(blob)\n",
        "    detections = net.forward()\n",
        "    person_count = 0\n",
        "\n",
        "    for i in np.arange(0, detections.shape[2]):\n",
        "        confidence = detections[0, 0, i, 2]\n",
        "        if confidence > CONFIDENCE_THRESHOLD:\n",
        "            idx = int(detections[0, 0, i, 1])\n",
        "            if CLASSES[idx] == \"person\":\n",
        "                person_count += 1\n",
        "                box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
        "                (startX, startY, endX, endY) = box.astype(\"int\")\n",
        "                cv2.rectangle(frame, (startX, startY), (endX, endY), (0, 255, 0), 2)\n",
        "\n",
        "    # Determine the crowd density level\n",
        "    if person_count < 5:\n",
        "        density_level = \"Low\"\n",
        "        color = (0, 255, 0)\n",
        "    elif person_count < 10:\n",
        "        density_level = \"Medium\"\n",
        "        color = (0, 255, 255)\n",
        "    else:\n",
        "        density_level = \"High\"\n",
        "        color = (0, 0, 255)\n",
        "\n",
        "    # Update global status\n",
        "    app_status['person_count'] = person_count\n",
        "    app_status['density_level'] = density_level\n",
        "    app_status['last_updated'] = time.time()\n",
        "\n",
        "    # Display info on the frame\n",
        "    cv2.putText(frame, f\"Person Count: {person_count}\", (10, 30),\n",
        "                cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 0), 2)\n",
        "    cv2.putText(frame, f\"Density: {density_level}\", (10, 60),\n",
        "                cv2.FONT_HERSHEY_SIMPLEX, 0.8, color, 2)\n",
        "\n",
        "    return frame\n",
        "\n",
        "def generate_frames():\n",
        "    \"\"\"Generator function for video streaming.\"\"\"\n",
        "    camera = cv2.VideoCapture(0)\n",
        "    if not camera.isOpened():\n",
        "        print(\"Error: Could not open video stream.\")\n",
        "        return\n",
        "\n",
        "    while True:\n",
        "        success, frame = camera.read()\n",
        "        if not success:\n",
        "            break\n",
        "        else:\n",
        "            processed_frame = analyze_frame(frame)\n",
        "            ret, buffer = cv2.imencode('.jpg', processed_frame)\n",
        "            frame_bytes = buffer.tobytes()\n",
        "            yield (b'--frame\\r\\n'\n",
        "                   b'Content-Type: image/jpeg\\r\\n\\r\\n' + frame_bytes + b'\\r\\n')\n",
        "    camera.release()\n",
        "\n",
        "# --- Flask Routes ---\n",
        "@app.route('/')\n",
        "def index():\n",
        "    \"\"\"Render the main web page.\"\"\"\n",
        "    return render_template('index.html')\n",
        "\n",
        "@app.route('/video_feed')\n",
        "def video_feed():\n",
        "    \"\"\"Video streaming route.\"\"\"\n",
        "    return Response(generate_frames(),\n",
        "                    mimetype='multipart/x-mixed-replace; boundary=frame')\n",
        "\n",
        "@app.route('/status')\n",
        "def status():\n",
        "    \"\"\"Endpoint to get the current crowd status.\"\"\"\n",
        "    return jsonify(app_status)\n",
        "\n",
        "@app.route('/generate_protocol', methods=['POST'])\n",
        "def generate_protocol():\n",
        "    \"\"\"\n",
        "    Endpoint to generate a safety protocol using the Gemini API.\n",
        "    \"\"\"\n",
        "    data = request.get_json()\n",
        "    person_count = data.get('person_count', 0)\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "    You are a security and safety expert. A CCTV system has detected a high-density crowd of approximately {person_count} people in a public area.\n",
        "    Generate a concise, clear, and actionable safety protocol for on-ground security personnel.\n",
        "    The protocol should be formatted in Markdown and include the following sections:\n",
        "    1.  **Immediate Actions:** 3-4 critical first steps.\n",
        "    2.  **Communication Protocol:** Who to contact and what to report.\n",
        "    3.  **Crowd Management Techniques:** 2-3 specific techniques to de-escalate the situation.\n",
        "    4.  **Emergency Preparedness:** Key reminders for potential evacuation or medical needs.\n",
        "    \"\"\"\n",
        "\n",
        "    # NOTE: In a real environment, the API key should be stored securely and not be empty.\n",
        "    # The Canvas environment handles API key injection automatically when it is an empty string.\n",
        "    api_key = \"\"\n",
        "    api_url = f\"https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key={api_key}\"\n",
        "\n",
        "    payload = {\n",
        "        \"contents\": [{\n",
        "            \"parts\": [{\n",
        "                \"text\": prompt\n",
        "            }]\n",
        "        }]\n",
        "    }\n",
        "\n",
        "    headers = {'Content-Type': 'application/json'}\n",
        "\n",
        "    try:\n",
        "        response = requests.post(api_url, headers=headers, data=json.dumps(payload), timeout=30)\n",
        "        response.raise_for_status() # Raise an exception for bad status codes\n",
        "        result = response.json()\n",
        "\n",
        "        if (result.get('candidates') and result['candidates'][0].get('content') and\n",
        "            result['candidates'][0]['content'].get('parts') and result['candidates'][0]['content']['parts'][0].get('text')):\n",
        "\n",
        "            generated_text = result['candidates'][0]['content']['parts'][0]['text']\n",
        "            return jsonify({'protocol': generated_text})\n",
        "        else:\n",
        "            # Handle cases where the response structure is unexpected\n",
        "            error_message = \"Error: Could not parse the response from the Gemini API.\"\n",
        "            if result.get('promptFeedback'):\n",
        "                error_message += f\" Reason: {result['promptFeedback'].get('blockReason')}\"\n",
        "            return jsonify({'error': error_message}), 500\n",
        "\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        return jsonify({'error': f\"API request failed: {e}\"}), 500\n",
        "\n",
        "\n",
        "# --- Main Execution ---\n",
        "if __name__ == '__main__':\n",
        "    app.run(debug=True)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "RjojopXFlHQQ"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}